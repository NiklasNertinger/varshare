Our work provided a simple and effective framework for skill and component reuse in the multi-task RL domain, which the community can build off. With the learned skill module, Our work can also inspire work on zero-shot skill transferring and sharing. 

With improved sample efficiency and potential zero-shot skill transfer, the community might be able to use reinforcement learning to solve tasks that not feasible before and build the robots that can generalize to different tasks. 
These robots could potentially bring lots of new possibilities in almost every aspect of people's daily life, e.g., self-driving cars and house-hold robots.  Besides, general learned robotics can also be useful for unseen or urgent out-of-distribution scenes. For instance, when it comes to performing a rescue under the earthquake, the robot should have the ability to cope with different conditions. 

In the deep learning era, collecting samples and training large models could consume a lot energy and release a massive amount of carbon dioxide. With better sample efficiency, training reinforcement learning policy for real-world settings can be much more environment-friendly. Meanwhile, better sample efficiency can also lower the bar and be more accessible for inexperienced researchers to get into the field.

{\noindent {\bf Acknowledgement}: This work is supported, in part, by grants from DARPA LwLL, NSF 1730158 CI-New: Cognitive Hardware and Software Ecosystem Community Infrastructure (CHASE-CI), NSF ACI-1541349 CC*DNI Pacific Research Platform,  a research grant from Qualcomm, and gift from TuSimple.}

